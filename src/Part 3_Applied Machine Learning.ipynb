{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Applied Machine Learning\n",
    "\n",
    "For this section, task will be to convert a small snippet of ML Python code implemented around pandas and sklearn into a functionally equivalent Spark version which may leverage Spark's ML or MLlib packages.\n",
    "\n",
    "We'll be working with the famous Iris data set which can be fetched from UCI's machine learning repository in CSV format: \n",
    "\n",
    "curl -L \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\" -o /tmp/iris.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem description:\n",
    "\n",
    "The Data Science team has provided prototype code in Python which builds a basic, Logistic Regression model on the Iris dataset. We want to predict the type of flower - denoted as class in the CSV - based upon the 4 features which relate to certain flower measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3_Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Executing the given python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kalyan kumar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\Kalyan kumar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\Kalyan kumar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "C:\\Users\\Kalyan kumar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\Kalyan kumar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\Kalyan kumar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "C:\\Users\\Kalyan kumar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\Kalyan kumar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\Kalyan kumar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n"
     ]
    }
   ],
   "source": [
    "# importing the libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the iris.data using pandas.read_csv and defining the schema\n",
    "\n",
    "df = pd.read_csv(\"iris.data\",\n",
    "names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width        class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#displaying the first 5 records\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features from class.\n",
    "\n",
    "array = df.values\n",
    "X = array[:,0:4]\n",
    "y = array[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kalyan kumar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kalyan kumar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit Logistic Regression classifier.\n",
    "\n",
    "logreg = LogisticRegression(C=1e5)\n",
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa']\n",
      "['Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "#displaying the predicted values\n",
    "\n",
    "print(logreg.predict([[5.1, 3.5, 1.4, 0.2]]))\n",
    "print(logreg.predict([[6.2, 3.4, 5.4, 2.3]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3_Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a Spark version of the above Python code and demonstrate that can correctly predict on the training data, similar to what was done in the preceding section.\n",
    "\n",
    "You should be able to run your model against the pred_data data frame in the code snippet:\n",
    "\n",
    "pred_data = spark.createDataFrame(\n",
    "[(5.1, 3.5, 1.4, 0.2),\n",
    "(6.2, 3.4, 5.4, 2.3)],\n",
    "[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"])\n",
    "\n",
    "Write out the prediction results to a CSV file out_3_2.txt :\n",
    "class\n",
    "<class 1>\n",
    "<class 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing PySpark\n",
    "\n",
    "#!pip install findspark\n",
    "\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing neccessary libraries\n",
    "\n",
    "import csv\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType, StringType\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the SparkSession\n",
    "\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining schema\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"sepal_length\", DoubleType(), True),\n",
    "    StructField(\"sepal_width\", DoubleType(), True),\n",
    "    StructField(\"petal_length\", DoubleType(), True),\n",
    "    StructField(\"petal_width\", DoubleType(), True),\n",
    "    StructField(\"class\", StringType(), True)])\n",
    "\n",
    "#loading iris.data into a dataFrame\n",
    "\n",
    "irisLoad_DF = spark.read.csv(\"iris.data\",schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisLoad_DF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|      class|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "|         5.1|        3.5|         1.4|        0.2|Iris-setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2|Iris-setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2|Iris-setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2|Iris-setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2|Iris-setosa|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#displaying the first 5 rows of a dataFrame\n",
    "\n",
    "irisLoad_DF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the column \"class\" as \"label\". Since class is a reserved keyword in Python\n",
    "\n",
    "irisRename_DF = irisLoad_DF.withColumnRenamed(\"class\",\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|      label|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "|         5.1|        3.5|         1.4|        0.2|Iris-setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2|Iris-setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2|Iris-setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2|Iris-setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2|Iris-setosa|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#displaying the first 5 rows of a dataFrame with renamed column \"label\"\n",
    "\n",
    "irisRename_DF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this step we are merging sepal_length,sepal_width,petal_length,petal_width columns into \n",
    "#one vector column \"features\" using VectorAssembler\n",
    "\n",
    "#VectorAssembler is a feature transformer that merges multiple columns into a vector column\n",
    "\n",
    "vectorAssembler_features = VectorAssembler(\n",
    "    inputCols=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"], outputCol=\"features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying VectorAssembler transformation to the Iris Dataframe\n",
    "\n",
    "irisTrans_DF = vectorAssembler_features.transform(irisRename_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+-----------------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|      label|         features|\n",
      "+------------+-----------+------------+-----------+-----------+-----------------+\n",
      "|         5.1|        3.5|         1.4|        0.2|Iris-setosa|[5.1,3.5,1.4,0.2]|\n",
      "|         4.9|        3.0|         1.4|        0.2|Iris-setosa|[4.9,3.0,1.4,0.2]|\n",
      "|         4.7|        3.2|         1.3|        0.2|Iris-setosa|[4.7,3.2,1.3,0.2]|\n",
      "|         4.6|        3.1|         1.5|        0.2|Iris-setosa|[4.6,3.1,1.5,0.2]|\n",
      "|         5.0|        3.6|         1.4|        0.2|Iris-setosa|[5.0,3.6,1.4,0.2]|\n",
      "+------------+-----------+------------+-----------+-----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#displaying first 5 records after VectorAssembler transformation\n",
    "\n",
    "irisTrans_DF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|      label|         features|\n",
      "+-----------+-----------------+\n",
      "|Iris-setosa|[5.1,3.5,1.4,0.2]|\n",
      "|Iris-setosa|[4.9,3.0,1.4,0.2]|\n",
      "|Iris-setosa|[4.7,3.2,1.3,0.2]|\n",
      "|Iris-setosa|[4.6,3.1,1.5,0.2]|\n",
      "|Iris-setosa|[5.0,3.6,1.4,0.2]|\n",
      "+-----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dropping sepal_length,sepal_width,petal_length,petal_width columns. Since already have these columns as features\n",
    "\n",
    "irisNew_DF = irisTrans_DF.drop(\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\")\n",
    "\n",
    "#displaying first 5 records after drop\n",
    "\n",
    "irisNew_DF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming dataframe by assigning labelIndex to every class of flower by using StringIndexer.\n",
    "\n",
    "#StringIndexer encodes a string column of labels to a column of label indices and can encode multiple columns.\n",
    "\n",
    "classlabel_indexer = StringIndexer(inputCol=\"label\", outputCol=\"labelIndex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying above StringIndexer transformation to the dataFrame\n",
    "\n",
    "irisIndexer_DF = classlabel_indexer.fit(irisNew_DF).transform(irisNew_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+----------+\n",
      "|      label|         features|labelIndex|\n",
      "+-----------+-----------------+----------+\n",
      "|Iris-setosa|[5.1,3.5,1.4,0.2]|       0.0|\n",
      "|Iris-setosa|[4.9,3.0,1.4,0.2]|       0.0|\n",
      "|Iris-setosa|[4.7,3.2,1.3,0.2]|       0.0|\n",
      "|Iris-setosa|[4.6,3.1,1.5,0.2]|       0.0|\n",
      "|Iris-setosa|[5.0,3.6,1.4,0.2]|       0.0|\n",
      "+-----------+-----------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#displaying first 5 records after StringIndexer transformation\n",
    "\n",
    "\n",
    "irisIndexer_DF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining logistic regression classifier model\n",
    "\n",
    "logReg_model = LogisticRegression(\n",
    "    labelCol=\"labelIndex\", featuresCol=\"features\", maxIter=100, regParam=0.001, elasticNetParam=1, standardization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data to trainingData and testData\n",
    "\n",
    "(training_Data, test_Data) = irisIndexer_DF.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 115\n",
      "Test Dataset Count: 35\n"
     ]
    }
   ],
   "source": [
    "#displaying Training Dataset and Test Dataset Count\n",
    "\n",
    "print(\"Training Dataset Count: \" + str(training_Data.count()))\n",
    "print(\"Test Dataset Count: \" + str(test_Data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting LR model to train logReg_modeling set\n",
    "\n",
    "lr_model_temp = logReg_model.fit(training_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions with the trained LR model on the test data\n",
    "\n",
    "predictions_testData = lr_model_temp.transform(test_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+----------+--------------------+--------------------+----------+\n",
      "|      label|         features|labelIndex|       rawPrediction|         probability|prediction|\n",
      "+-----------+-----------------+----------+--------------------+--------------------+----------+\n",
      "|Iris-setosa|[4.4,3.0,1.3,0.2]|       0.0|[10.2329081702599...|[0.99966927192950...|       0.0|\n",
      "|Iris-setosa|[4.6,3.1,1.5,0.2]|       0.0|[10.2223335702676...|[0.99962047317704...|       0.0|\n",
      "|Iris-setosa|[4.6,3.4,1.4,0.3]|       0.0|[11.3819150595923...|[0.99992189484564...|       0.0|\n",
      "|Iris-setosa|[4.7,3.2,1.6,0.2]|       0.0|[10.4540068620724...|[0.99969982792209...|       0.0|\n",
      "|Iris-setosa|[4.8,3.0,1.4,0.3]|       0.0|[9.39627834922738...|[0.99883777701009...|       0.0|\n",
      "+-----------+-----------------+----------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Displaying the predictions on test data\n",
    "\n",
    "predictions_testData.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar to the given python code, now training the model on the entire data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting LR model to train on entire dataset\n",
    "\n",
    "lr_model = logReg_model.fit(irisIndexer_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a spark dataframe with the given values as per the task\n",
    "\n",
    "pred_data = spark.createDataFrame(\n",
    "[(5.1, 3.5, 1.4, 0.2),\n",
    "(6.2, 3.4, 5.4, 2.3)],\n",
    "[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transofrming the input dataframe to convert the columns to vectors(features)\n",
    "\n",
    "pred_data_new = vectorAssembler_features.transform(pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the label(flower class) for the given input dataframe\n",
    "\n",
    "pred_data_predictions = lr_model.transform(pred_data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "|         features|prediction|\n",
      "+-----------------+----------+\n",
      "|[5.1,3.5,1.4,0.2]|       0.0|\n",
      "|[6.2,3.4,5.4,2.3]|       2.0|\n",
      "+-----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#displaying the predictions along with the features for given input data\n",
    "\n",
    "pred_data_predictions.select(\"features\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The model has predicted the class of the flowers (label) correctly for the given input dataframe as per the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming prediction as Class\n",
    "\n",
    "pred_data_out = pred_data_predictions.select(col(\"prediction\").alias(\"Class\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|Class|\n",
      "+-----+\n",
      "|  0.0|\n",
      "|  2.0|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#displaying only Class column with the values\n",
    "\n",
    "pred_data_out.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing out the prediction results to a CSV file: out_3_2.txt\n",
    "\n",
    "pred_data_out.repartition(1).write.mode(\"overwrite\").format(\"csv\").option(\"header\", \"true\").save(\"out_3_2.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                           The End. Thank you! :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
